{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268b101f-51e9-4fea-bd36-f8f137daa2d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Real-time fraud detection with vector search for MemoryDB\n",
    "\n",
    "## 1. Components\n",
    "![Packages](images/AWS-OnAir_01-Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f5035-2003-4eeb-b5ee-dbf117e34adc",
   "metadata": {},
   "source": [
    "## 2. Install packages\n",
    "![Packages](images/AWS-OnAir_02-Packages.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac063a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (24.3.1)\n",
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: valkey in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (6.0.2)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from valkey) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install/upgrade pip and other packages in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install -U valkey # Note the Valkey library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8db2060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from valkey.commands.search.field import VectorField, TextField\n",
    "from valkey.commands.search.field import NumericField, TagField\n",
    "from valkey.commands.search.query import Query\n",
    "from valkey.commands.search.result import Result\n",
    "from valkey.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from valkey.cluster import ValkeyCluster as MemoryDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e4186",
   "metadata": {},
   "source": [
    "## 3. Connect to MemoryDB\n",
    "![Packages](images/AWS-OnAir_03-Connection.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37ac1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping status of MemoryDB = True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv('env.txt')\n",
    "\n",
    "memorydb_host = os.environ.get(\"MEMORYDB_HOST\", \"localhost\")\n",
    "memorydb_port = os.environ.get(\"MEMORYDB_PORT\", 6379)\n",
    "\n",
    "mdb = MemoryDB(host=memorydb_host, port=memorydb_port, ssl=True, decode_responses=False, ssl_cert_reqs=\"none\")\n",
    "\n",
    "print(\"Ping status of MemoryDB = \" + str(mdb.ping()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597ee7c-5326-4c88-99f5-b2510b8ce01f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. [Credit Card Fraud Detection Source](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
    "\n",
    "Originally from Kaggle.\n",
    "\n",
    "This dataset presents transactions that occurred in two days, where we have __492__ _frauds_ out of __284,807__ _transactions_.  \n",
    "The dataset is highly unbalanced, the 1 Class (_frauds_) account for __0.172%__ of all _transactions_.\n",
    "\n",
    "It contains only numerical input variables:\n",
    "    \n",
    "- Feature __'Time'__ contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- Features __V1__, __V2__, and __V28__ Are 28 dimensions of vectorized (_embeddings created_) data representing transaction details such a time location and so on.\n",
    "- Feature __'Amount'__ is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning.\n",
    "- Feature __'Class'__ is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "![Packages](images/AWS-OnAir_04-NeedleHaystack.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e770bc-e934-4703-b90f-e823535c5cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "\n",
    "print(f\"Number of rows in dataset: {df.shape[0]:,} Number of columns: {df.shape[1]:,}\\n\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b26c63-692b-4a42-8aed-5b31ce3cb909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validate data\n",
    "# Ensure the specified columns exist in the DataFrame\n",
    "\n",
    "embedding_columns = [f'V{i}' for i in range(1, 29)]\n",
    "\n",
    "missing_columns = [col for col in embedding_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"The following embedding columns are missing from the DataFrame: {missing_columns}\")\n",
    "\n",
    "df['Vector'] = df[embedding_columns].values.tolist()\n",
    "\n",
    "print(f\"Number of columns in dataset: {df.shape[1]:,}\\n\")\n",
    "print(f\"{df['Vector'].head().to_string()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c7ce7",
   "metadata": {},
   "source": [
    "## 5. Create index in MemoryDB\n",
    "\n",
    "![Packages](images/AWS-OnAir_05-Index.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d1384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_key(prefix = \"\"):\n",
    "    return prefix + str(uuid.uuid4())\n",
    "\n",
    "def create_hnsw_index(mdb, index_name, vector_field_name, initial_size, \n",
    "                      vector_dimensions=len(embedding_columns), distance_metric='L2', M_EDGES=16, EF_CONSTRUCT=512, key_prefix=''):\n",
    "    # Create the MemoryDB index\n",
    "    # larger M value increases the number of edges thus creating a more connected graph helping with recall but consumes more memory\n",
    "    # Larger EF_CONSTRUCTION has a larger dynamic candidate list during construction. This leads to a more thorough search during construction and longer construction time\n",
    "    # Larger EF_RUNTIME examines more vectors during query execution resulting in better recall but taking longer to complete left at default value of 10\n",
    "    # Distance Metrics L2->Euclidean distance. | IP->Dot product | COSINE->the angle between vectors\n",
    "\n",
    "    # Drop the index if it exits so that you can re-run this block of code.\n",
    "    # print( mdb.ft(index_name).info())\n",
    "\n",
    "    # Create a new index\n",
    "    try:\n",
    "        mdb.ft(index_name).create_index([\n",
    "            VectorField(vector_field_name, \n",
    "                        \"HNSW\", {\n",
    "                            \"TYPE\": \"FLOAT32\",\n",
    "                            \"DIM\": vector_dimensions,\n",
    "                            \"DISTANCE_METRIC\": distance_metric,\n",
    "                            \"INITIAL_CAP\": initial_size,\n",
    "                            \"M\": M_EDGES,\n",
    "                            \"EF_CONSTRUCTION\": EF_CONSTRUCT\n",
    "                        }\n",
    "                ),\n",
    "            NumericField(\"amount\"),\n",
    "            NumericField(\"class\")\n",
    "            ],\n",
    "            definition=IndexDefinition(prefix=[key_prefix])\n",
    "        )\n",
    "        print(f\"Index {index_name} created successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Index {index_name} created previously: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239f017",
   "metadata": {},
   "source": [
    "## Behind the scenes\n",
    "```\n",
    "FT.CREATE \"ccfd_hnsw_index\"\n",
    "ON HASH\n",
    "PREFIX \"1\" \"tsx:\"\n",
    "SCHEMA \"vector\" \n",
    "VECTOR \"HNSW\" \"12\" \"TYPE\" \"FLOAT32\" \"DIM\" \"28\" \"DISTANCE_METRIC\" \"Cosine\" \n",
    "INITIAL_CAP \"274807\" \"M\" \"16\" \n",
    "EF_CONSTRUCTION \"512\" \"amount\" \"NUMERIC\" \"class\" \"NUMERIC\"\n",
    "```\n",
    "\n",
    "![Packages](images/AWS-OnAir_08-KNNdistanceMetrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b1fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KEY_PREFIX = \"tsx:\"\n",
    "vector_field_name = \"VEC\"\n",
    "index_name = \"ccfd_hnsw_index\"\n",
    "number_of_vectors = len(df[df[\"Class\"] == 1]) - 10   # do not add the last 10 fraudulent rows\n",
    "vector_dimensions = len(embedding_columns)       # vector dimension is the number of embedded/vector columns only\n",
    "\n",
    "print(f\"Creating Vector Index {index_name} on Field {vector_field_name} Expecting {number_of_vectors:,} vectors\")\n",
    "\n",
    "# First clean up  MemoryDB\n",
    "mdb.flushall()\n",
    "# mdb.ft(index_name).dropindex()\n",
    "\n",
    "# Create an emtpy index in MemoryDB\n",
    "create_hnsw_index(mdb, index_name, vector_field_name, number_of_vectors, \n",
    "                 vector_dimensions=vector_dimensions, distance_metric='Cosine', M_EDGES=16, EF_CONSTRUCT=512, key_prefix=KEY_PREFIX)\n",
    "\n",
    "print(f\"\\nVector Information: {mdb.ft(index_name).info()}\")\n",
    "print(f\"\\nNumber of indexed vectors: {mdb.ft(index_name).info()['num_indexed_vectors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4ac26",
   "metadata": {
    "tags": []
   },
   "source": [
    "6. Load vector embeddings into MemoryDB\n",
    "\n",
    "![Index](images/AWS-OnAir_06-Load.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1391e-f619-4c72-8c76-b9c3e0e3817e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load data into MemoryDB\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Import tqdm for jupyter notebook\n",
    "from tqdm.notebook import tqdm\n",
    "# Enable tqdm for Pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "count = 0\n",
    "pipe = mdb.pipeline()\n",
    "\n",
    "for index, row in tqdm(df.loc[df['Class'] == 1].iloc[:number_of_vectors-1].iterrows(), total=number_of_vectors-1):\n",
    "#for index, row in tqdm(df.iloc[:250000].iterrows(), total=250000):\n",
    "    \n",
    "    key = generate_key(prefix=KEY_PREFIX)\n",
    "    vector = np.array(row['Vector'], dtype=np.float32).tobytes()\n",
    "    \n",
    "    pipe.hset(key, mapping={\n",
    "        vector_field_name: vector,\n",
    "        'amount': row['Amount'],\n",
    "        'class': row['Class']\n",
    "        })\n",
    "    \n",
    "    if index % BATCH_SIZE == 0:\n",
    "        pipe.execute()\n",
    "        pipe = mdb.pipeline()\n",
    "    count += 1\n",
    "    \n",
    "pipe.execute()\n",
    "\n",
    "print(f\"\\nData indexed successfully. Keys created: {count}\\n\")\n",
    "print(f\"Indexed info: {mdb.ft(index_name).info()}\")\n",
    "time.sleep(1)\n",
    "print(f\"\\nNumber of indexed vectors: {mdb.ft(index_name).info()['num_indexed_vectors']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf9ca5",
   "metadata": {},
   "source": [
    "## 7. Find fraudulent transactions\n",
    "\n",
    "![Find-Tsx](images/AWS-OnAir_07-Find.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6cdf1-24a1-45d6-b8a0-30002680a4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_search(mdb, index_name, query_vector, top_n=5):\n",
    "\n",
    "    # Convert the query vector to bytes\n",
    "    query_vector_bytes = np.array(query_vector, dtype=np.float32).tobytes()\n",
    "\n",
    "    # Create the query\n",
    "    query = Query(f\"*=>[KNN {top_n} @VEC $query_vec AS score ]\") \\\n",
    "        .sort_by(\"score\") \\\n",
    "        .return_fields(\"score\", \"amount\", \"class\") \\\n",
    "        .paging(0, top_n) \\\n",
    "        .dialect(2)\n",
    "\n",
    "    params = {\n",
    "        \"query_vec\": query_vector_bytes,\n",
    "        \"EF_RUNTIME\": 10\n",
    "    }\n",
    "\n",
    "    # Process the query\n",
    "    result = mdb.ft(index_name).search(query, query_params=params).docs\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91170b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result = df.query('Class == 1')['Amount'].tail(10)\n",
    "print(result.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cca6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query_vector = df.iloc[281143]['Vector']\n",
    "\n",
    "results = similarity_search(mdb, index_name, query_vector, top_n=5)\n",
    "\n",
    "# print(results)\n",
    "\n",
    "for doc in results:\n",
    "        score = round(1 - float(doc.score), 2)\n",
    "        id = doc.id\n",
    "        print(f\"Vector {id} has a score {score}\")\n",
    "        # amount = doc.amount\n",
    "        # print(f\"Vector {id} has a score {score} for the amount {amount}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5bc51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query behind the scenes\n",
    "\n",
    "```\n",
    "FT.SEARCH \"ccfd_hnsw_index\" \"*=>[KNN 5 @vector $query_vec AS score]\" \n",
    "RETURN \"2\" \"amount\" \"class\" \n",
    "SORTBY \"score\" \"ASC\" \"DIALECT\" \"2\" \"LIMIT\" \"0\" \"5\" \n",
    "\"params\" \"2\" \"query_vec\" \"\\x1e!2\\xbf\\x0b\\xef\\x14?\\x184\\x18@\\xbd\\xd5\\x81=?\\x82\\xa8>\\xa5T\\xe6\\xbe\\...\\xbf\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98618c-b84f-4c21-83c7-5730ee33f103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "print('#' * 50)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    match i:\n",
    "        case 3:\n",
    "            i = 281144\n",
    "            row = df.iloc[i]\n",
    "        case 5:\n",
    "            i = 4920\n",
    "            row = df.iloc[i]\n",
    "        case _:\n",
    "            i = random.randint(0, 250_000)\n",
    "            row = df.iloc[i]\n",
    "\n",
    "    vector = row['Vector']\n",
    "    results = similarity_search(mdb, index_name, vector, top_n=5)\n",
    "    print(f\"Classification {row.Class} Transaction ID {i}\")\n",
    "    print(row.Class)\n",
    "    for doc in results:\n",
    "        score = round(1 - float(doc.score), 2)\n",
    "        id = doc.id\n",
    "        print(f\"Index: Vector {id} has a score {score}\")\n",
    "        \n",
    "    print('#' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b22d5a-8b9c-41cd-9126-e536d82ac08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
