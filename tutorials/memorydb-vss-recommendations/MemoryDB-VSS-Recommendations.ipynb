{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c25378",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c6872",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how one might use MemoryDB as a recommendation engine.\n",
    "\n",
    "In this Notebook, we utilize [Amazon Bedrock to create vector embeddings for text](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html) whenever necessary. This includes the initial creation of vector embeddings for the dataset we have. We also use it to create embeddings of the text we provide to MemoryDB during a [vector similarity search (VSS)](https://docs.aws.amazon.com/memorydb/latest/devguide/vector-search-overview.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f67aa",
   "metadata": {},
   "source": [
    "## SECTION 1 - SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b85b8",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e32b0",
   "metadata": {},
   "source": [
    "Before beginning, you must have the following:\n",
    "\n",
    "- MemoryDB Cluster with:\n",
    "  - VSS Enabled\n",
    "  - TLS Enabled\n",
    "  - Username and password with sufficient permissions\n",
    "- Access to Amazon Bedrock for embeddings\n",
    "- Access to either:\n",
    "  - Amazon Sagemaker AI Notebooks\n",
    "  - OR\n",
    "  - An EC2 system running Jupyter Notebook that has connectivity to MemoryDB.\n",
    "\n",
    "The Amazon SageMaker AI Notebook or EC2 system must have at least 100 GB of storage free."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfc656",
   "metadata": {},
   "source": [
    "### Setup credential information\n",
    "\n",
    "Create or modify the `env` file to include the following variables\n",
    "\n",
    "- `MEMORYDB_ENDPOINT` (ex: \"clustercfg....memorydb.us-east-1.amazonaws.com\")\n",
    "- `MEMORYDB_USERNAME` (ex: \"my_username\")\n",
    "- `MEMORYDB_PASSWORD` (ex: \"my_password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737eadb",
   "metadata": {},
   "source": [
    "### Install Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf9260-2b10-4614-8fce-de80d0d730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import importlib.util\n",
    "import sys\n",
    "def install_if_missing(package):\n",
    "    if importlib.util.find_spec(package) is None:\n",
    "        !{sys.executable} -m pip install {package}\n",
    "        \n",
    "packages = ['valkey[libvalkey]', 'requests', 'pandas', 'python-dotenv',\n",
    "            'boto3', 'botocore', 'langchain_aws', 'redis', 'numpy', 'langchain']\n",
    "\n",
    "for package in packages:\n",
    "    install_if_missing(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57a2eb0-79ff-4cdd-9f7b-033545c8e91c",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b27829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.parse import quote_plus\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "from botocore.exceptions import ClientError\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain_aws.vectorstores.inmemorydb import (\n",
    "    InMemoryDBTag,\n",
    "    InMemoryVectorStore,\n",
    ")\n",
    "from langchain_aws.vectorstores.inmemorydb.filters import InMemoryDBFilterExpression\n",
    "from valkey.cluster import ValkeyCluster as MemoryDBCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b36456",
   "metadata": {},
   "source": [
    "### Load configuration values from environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('env')\n",
    "MEMORYDB_ENDPOINT = os.getenv('MEMORYDB_ENDPOINT')\n",
    "MEMORYDB_USERNAME = os.getenv('MEMORYDB_USERNAME')\n",
    "MEMORYDB_PASSWORD = os.getenv('MEMORYDB_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376eeb6",
   "metadata": {},
   "source": [
    "### Define global variables for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5816f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORYDB_CLUSTER_URI = f\"rediss://{MEMORYDB_USERNAME}:{MEMORYDB_PASSWORD}@{MEMORYDB_ENDPOINT}\"\n",
    "\n",
    "MAX_MOVIES = 15000\n",
    "\n",
    "MAX_PLOT_LENGTH = 250\n",
    "\n",
    "# Which metadata field names to use, and in the specific order\n",
    "metadata_field_names = ['plot', 'release_date',\n",
    "                        'content', 'genres', 'actors', 'movie_name', 'movie_id']\n",
    "\n",
    "INDEX_NAME = 'movie_index'\n",
    "MOVIE_DATA_URL = 'https://www.cs.cmu.edu/~ark/personas/data'\n",
    "ORIGINAL_MOVIE_FILE = 'MovieSummaries.tar.gz'\n",
    "DATASET_DIR = 'datasets'\n",
    "COMPRESSED_FILE = f'{DATASET_DIR}/{ORIGINAL_MOVIE_FILE}'\n",
    "FULL_DATASET_PATH = f'{DATASET_DIR}/MovieSummaries'\n",
    "MOVIE_TSV = f'{FULL_DATASET_PATH}/movie.metadata.tsv'\n",
    "ACTOR_TSV = f'{FULL_DATASET_PATH}/character.metadata.tsv'\n",
    "PLOTS_TSV = f'{FULL_DATASET_PATH}/plot_summaries.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61042a58",
   "metadata": {},
   "source": [
    "## SECTION 2 - DOWNLOAD AND EXTRACT DATA\n",
    "\n",
    "In this section we download a movie dataset including movies, actors and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648df459",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Wait until you see \"DONE\" after executing this cell before moving on.')\n",
    "print('There are several steps and it could take a minute.\\n')\n",
    "# Create a new directory if it doesn't exist\n",
    "if not os.path.exists(f\"{DATASET_DIR}\"):\n",
    "    print(f'Creating dataset directory \\'{DATASET_DIR}\\'\\n')\n",
    "    os.makedirs(f\"{DATASET_DIR}\")\n",
    "else:\n",
    "    print(\n",
    "        f'Dataset directory \\'{DATASET_DIR}\\' already exists, skipping creation of directory.\\n')\n",
    "\n",
    "if not os.path.isfile(COMPRESSED_FILE):\n",
    "    DOWNLOAD_URL = f'{MOVIE_DATA_URL}/{ORIGINAL_MOVIE_FILE}'\n",
    "    print(f'Starting download of {DOWNLOAD_URL}\\n', flush=True)\n",
    "    response = requests.get(f'{DOWNLOAD_URL}')\n",
    "    print(f'Saving to {COMPRESSED_FILE}\\n')\n",
    "    with open(COMPRESSED_FILE, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    print(f'Found {COMPRESSED_FILE}, skipping download.\\n')\n",
    "\n",
    "if not os.path.exists(FULL_DATASET_PATH):\n",
    "    print(f'Extracting {COMPRESSED_FILE}.\\n', flush=True)\n",
    "    with tarfile.open(COMPRESSED_FILE, 'r:gz') as tar:\n",
    "        tar.extractall(path=f'{DATASET_DIR}')\n",
    "else:\n",
    "    print(\n",
    "        f'Compressed file {COMPRESSED_FILE} has already been extracted. Skipping.\\n')\n",
    "\n",
    "print('DONE\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f62383-fba3-4e36-8ece-8e09bed66608",
   "metadata": {},
   "source": [
    "### Helper function to remove Freebase ID information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fae873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use this function because the source dataset has\n",
    "# an old Freebase unique ID value, which is confusing to\n",
    "# work with, and we do not need it, only the values.\n",
    "\n",
    "def convert_freebase_kv_pairs(field_string):\n",
    "    try:\n",
    "        # Convert string to dictionary\n",
    "        field_dict = ast.literal_eval(field_string)\n",
    "        # Extract only the values (descriptions)\n",
    "        return list(field_dict.values())\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []  # Return an empty list if parsing fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7aabe",
   "metadata": {},
   "source": [
    "### Load Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88860d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movie_column_names = [\n",
    "    'movie_id', 'freebase_movie_id', 'movie_name', 'release_date',\n",
    "    'revenue', 'runtime', 'languages', 'countries', 'genres'\n",
    "]\n",
    "movie_include_columns = ['movie_id', 'movie_name', 'release_date', 'genres']\n",
    "\n",
    "# Read TSV into a DataFrame, keeping only the included columns\n",
    "movies_df = pd.read_csv(\n",
    "    f'{MOVIE_TSV}',\n",
    "    sep='\\t',\n",
    "    names=movie_column_names,\n",
    "    usecols=movie_include_columns,\n",
    "    index_col='movie_id',\n",
    "    nrows=MAX_MOVIES\n",
    ")\n",
    "\n",
    "# Convert genres field into a list\n",
    "movies_df['genres'] = movies_df['genres'].apply(convert_freebase_kv_pairs)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1654d",
   "metadata": {},
   "source": [
    "### Load Actor Data\n",
    "\n",
    "The data file has one line per actor, so we have to import the actors, and then group them together based on movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "actor_column_names = [\n",
    "    'movie_id', 'freebase_movie_id', 'release_date', 'character_name', 'actor_dob',\n",
    "    'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age_at_movie',\n",
    "    'freebase_character_map', 'misc1', 'misc2']\n",
    "actor_include_columns = ['movie_id', 'actor_name']\n",
    "initial_actors_df = pd.read_csv(\n",
    "    f'{ACTOR_TSV}',\n",
    "    sep='\\t',\n",
    "    names=actor_column_names,\n",
    "    usecols=actor_include_columns\n",
    ")\n",
    "\n",
    "# Drop nan values\n",
    "nan_actors_df = initial_actors_df.dropna()\n",
    "\n",
    "# Group actors based on movie_id\n",
    "actors_df = nan_actors_df.groupby(\n",
    "    'movie_id')['actor_name'].apply(list).reset_index()\n",
    "\n",
    "# Rename the column containing grouped actor_name values to 'actors'\n",
    "actors_df.columns = ['movie_id', 'actors']\n",
    "actors_df = actors_df.set_index('movie_id')\n",
    "\n",
    "actors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1457a6",
   "metadata": {},
   "source": [
    "### Load Movie Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plots_column_names = ['movie_id', 'plot']\n",
    "plots_include_columns = ['movie_id', 'plot']\n",
    "\n",
    "initial_plots_df = pd.read_csv(\n",
    "    f'{PLOTS_TSV}',\n",
    "    sep='\\t',\n",
    "    names=plots_column_names,\n",
    "    usecols=plots_include_columns,\n",
    "    index_col='movie_id'\n",
    ")\n",
    "\n",
    "# remove nans\n",
    "plots_df = initial_plots_df.dropna()\n",
    "# Remove remnants of Wikipedia \"{{Expand section}}\" comments\n",
    "plots_df['plot'] = plots_df['plot'].replace(\"{{Expand section}}\", \"\")\n",
    "\n",
    "plots_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945095ef",
   "metadata": {},
   "source": [
    "### Merge all 3 datasets (movie, actors, and move plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all 3 data frames into a single data frame\n",
    "FULL_MOVIE_DATASET = pd.concat([movies_df, actors_df, plots_df], axis=1)\n",
    "\n",
    "# If we have more than MAX_MOVIES, reduce the size\n",
    "FULL_MOVIE_DATASET = FULL_MOVIE_DATASET.iloc[:MAX_MOVIES]\n",
    "\n",
    "# remove any entries that have NaN in any column\n",
    "FULL_MOVIE_DATASET = FULL_MOVIE_DATASET.dropna()\n",
    "\n",
    "print(f'Resulted in {len(FULL_MOVIE_DATASET)} total movies.\\n')\n",
    "FULL_MOVIE_DATASET.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bbd2f",
   "metadata": {},
   "source": [
    "## SECTION 3 - PREP MEMORYDB FOR VECTOR STORE USAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82d2ec",
   "metadata": {},
   "source": [
    "### Function to convert String into List of Strings\n",
    "\n",
    "This function is required to turn a String of multiple values such as  `'Value 1, Value 2, Value 3'` into a List of Strings like `['Value 1', 'Value 2', Value 3']`. This is required if we want to use MemoryDB's TAG functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_metadata(row):\n",
    "    metadata = row.to_dict()  # Convert row to dictionary\n",
    "    for key, value in metadata.items():\n",
    "        # Convert ndarray to a list\n",
    "        if isinstance(value, np.ndarray):\n",
    "            metadata[key] = [f'\"{item}\"' for item in value.tolist()]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281133c",
   "metadata": {},
   "source": [
    "### Create collection of Langchain Document objects.\n",
    "\n",
    "This simplifies the creation of text embeddings for the data. We will use this collection in the subsequent step when we create the MemoryDB VSS index and ingest the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bca3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Documents from the DataFrame\n",
    "ALL_DOCS = []\n",
    "\n",
    "counter = 0\n",
    "for index, row in FULL_MOVIE_DATASET.iterrows():\n",
    "\n",
    "    metadata = preprocess_metadata(row)\n",
    "    metadata['movie_id'] = str(index)\n",
    "    content = f\"Movie: {row['movie_name']}\\n\"\n",
    "    content += f\"Release Date: {row['release_date']}\\n\"\n",
    "    content += f\"Genres: {row['genres']}\\n\"\n",
    "    content += f\"Actors: {row['actors']}\\n\"\n",
    "    content += f\"Plot: {row['plot']}\\n\"\n",
    "\n",
    "    # Create a Document object\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    ALL_DOCS.append(doc)\n",
    "\n",
    "print(f'Created {len(ALL_DOCS)} LangChain Documents.\\n', flush=True)\n",
    "\n",
    "# Uncommment the following field to display the first document to validate.\n",
    "#ALL_DOCS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32c6ea",
   "metadata": {},
   "source": [
    "### Get vector embeddings for all documents from Amazon Bedrock, then import into MemoryDB vector store\n",
    "\n",
    "**Note**: For 6,500 documents of this size, this usually takes about 9 minutes when using a remote embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    ALL_DOCS,\n",
    "    embedding=BedrockEmbeddings(),\n",
    "    redis_url=MEMORYDB_CLUSTER_URI,\n",
    "    index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b057e",
   "metadata": {},
   "source": [
    "### Setup MemoryDB client to run various Valkey commands\n",
    "\n",
    "This following cell creates is a connection to MemoryDB to perform operations such as [HMGET](https://valkey.io/commands/hmget/). It is not what we will use for Vector-based searches. That is defined in the `perform_query` function later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_client = MemoryDBCluster.from_url(\n",
    "    MEMORYDB_CLUSTER_URI, decode_responses=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b0b8f",
   "metadata": {},
   "source": [
    "### Show VSS index information\n",
    "\n",
    "Here we use the MemoryDB client we created in the previous cell to execute the [FT.INFO](https://docs.aws.amazon.com/memorydb/latest/devguide/vector-search-commands-ft.info.html) command to get information about the VSS index. As a reminder, this client can be used to perform any valid MemoryDB [command](https://valkey.io/commands/) and is not specific to vector searches.\n",
    "\n",
    "When executing this cell, review the output of the command.\n",
    "\n",
    "Notice that some fields are of type `TAG` (such as actors and genres). This is because when we created the LangChain documents, we included those as `metadata` fields. And because they were each a List of strings, LangChain automatically determined these should be configured to use as tags.\n",
    "\n",
    "Notice also that the `content_vector` field is of type `VECTOR`. This field is where the vector embeddings are stored and is specifically what we query when we perform a vector similarity search later on. This field is the embedded equivalent of the text field `content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a277a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_client.ft(INDEX_NAME).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb59ab1",
   "metadata": {},
   "source": [
    "## SECTION 4 - QUERYING AND ENRICHING DOCUMENTS WITH METADATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ac2ec",
   "metadata": {},
   "source": [
    "### Primary vector search function\n",
    "\n",
    "The following `perform_query` function will be called whenever we perform a vector search on MemoryDB.\n",
    "\n",
    "This will use the [LangChain AWS InMemoryVectorStore](https://api.python.langchain.com/en/latest/aws/vectorstores/langchain_aws.vectorstores.inmemorydb.base.InMemoryVectorStore.html) class, which will automatically create a vector embedding for the query text that we pass into it, which it then uses under the covers with the [FT.SEARCH](https://docs.aws.amazon.com/memorydb/latest/devguide/vector-search-commands-ft.search.html) command.\n",
    "\n",
    "Note that it uses the [similarity_search_with_relevance_scores](https://api.python.langchain.com/en/latest/aws/vectorstores/langchain_aws.vectorstores.inmemorydb.base.InMemoryVectorStore.html#langchain_aws.vectorstores.inmemorydb.base.InMemoryVectorStore.similarity_search_with_relevance_scores) function. It could also use the `similarity_search` function which does not include the score. We included it here as we want to show what the relevancy score was based on the query.\n",
    "\n",
    "Finally of note: we provide the `BedrockEmbeddings` function to create an embedding which provides the vector equivalent of the `query` field so that we can perform fast vector searches in MemoryDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query, k=15, filter=None):\n",
    "    memorydb_vss_client = InMemoryVectorStore(\n",
    "        redis_url=MEMORYDB_CLUSTER_URI,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=BedrockEmbeddings()\n",
    "    )\n",
    "    results = memorydb_vss_client.similarity_search_with_relevance_scores(\n",
    "        query, k=k, filter=filter)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5aee3-b7f8-46f7-ad9e-815283596f2c",
   "metadata": {},
   "source": [
    "### Create functions for metadata\n",
    "\n",
    "**Note** again that we are using LangChain (AWS) InMemoryVectorStore. The search functions available in that class do not automatically return all of the fields from MemoryDB, such as `genres`, `actors`, etc. Because of this, we need to create the following helper functions to fetch that metadata from MemoryDB.\n",
    "\n",
    "In the future, the `InMemoryVectorStore` search functions may have the ability to provide more fields from MemoryDB. In that case, the following functions could be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb666cb",
   "metadata": {},
   "source": [
    "### Function to fetch all movie data from MemoryDB\n",
    "\n",
    "This function takes a MemoryDB key name and fetches all of the metadata fields defined in `metadata_field_names` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we simplify creating a Dictionary by using the `metadata_field_names`\n",
    "# defined in the GLOBALS cell at the top.\n",
    "def get_metadata_from_mdb(_id):\n",
    "    mdb_result = mdb_client.hmget(_id, metadata_field_names)\n",
    "    result_dict = dict(zip(metadata_field_names, mdb_result))\n",
    "    result_dict['id'] = _id  # add the key name as part of the metadata\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355fbc5",
   "metadata": {},
   "source": [
    "### Function to enrich an existing LangChain Document\n",
    "\n",
    "Now that we have the ability to fetch metadata from MemoryDB, we can use it to enrich a LangChain document. We fetch the MemoryDB key name which is currently the only metadata field that is returned from a similarity search, and is located in the `metadata['id']` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata fields from MemoryDB and insert them into the LangChain Document\n",
    "def enrich_doc_from_mdb(_doc):\n",
    "    metadata = get_metadata_from_mdb(_doc.metadata['id'])\n",
    "    new_doc = Document(page_content=_doc.page_content, metadata=metadata)\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29339edf",
   "metadata": {},
   "source": [
    "### Function to enrich a collection of LangChain Documents\n",
    "\n",
    "Now that we have defined a function to enrich a LangChain Document (`enrich_doc_from_mdb`) by adding it's metadata (`get_metadata_from_mdb`), we need to have a way to enrich the **all** of the results of a vector search query, which is a collection of LangChain Documents. So we iterate through the results and enrich each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16750e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_documents(vss_response):\n",
    "    doc_list = list(map(itemgetter(0), vss_response))\n",
    "    score_list = list(map(itemgetter(1), vss_response))\n",
    "    new_doc_list = []\n",
    "    for entry in vss_response:\n",
    "        doc = entry[0]\n",
    "        score = entry[1]\n",
    "        key_name = doc.metadata['id']\n",
    "        new_doc = enrich_doc_from_mdb(doc)\n",
    "        entry = (new_doc, score)\n",
    "        new_doc_list.append(entry)\n",
    "    return new_doc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e90bf",
   "metadata": {},
   "source": [
    "## SECTION 5 - INITIAL MOVIE SEARCH\n",
    "\n",
    "This section is primarily to provide an initial set of movies. It is not an actual recommendation (yet!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe186f-c0d3-40b1-b269-22d96e2e072f",
   "metadata": {},
   "source": [
    "### Verify Functionality\n",
    "\n",
    "The next step verifies we are able to perform a vector search based on the search terms provided in the `query` field below, enrich the results, and then print those results.\n",
    "\n",
    "We only print information about the first LangChain Document (`enriched_results[0][0]`) from the results. We explicitly print out the LangChain Document's `metadata` and `page_content` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdb4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RESULTS = 10\n",
    "\n",
    "query = \"universe, planets, space, adventure\"\n",
    "results = perform_query(query, k=NUM_RESULTS)\n",
    "enriched_results = enrich_documents(results)\n",
    "print ('** METADATA:\\n')\n",
    "print (f'{enriched_results[0][0].metadata}\\n')\n",
    "print ('** PAGE CONTENT:\\n')\n",
    "print (f'{enriched_results[0][0].page_content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54624fbe",
   "metadata": {},
   "source": [
    "### Optional Filtering\n",
    "\n",
    "MemoryDB provides the flexibility to filter search results.\n",
    "\n",
    "Below you can see we are providing a LangChain `InMemoryDBTag` as a filter on the `genres` field. We are telling it to filter the results so that only movies that have the `Action` genre in the `genres` field are included in the final result.\n",
    "\n",
    "Depending upon the initial query you provided, the result below should be different than the result above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50930cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_condition = InMemoryDBTag('genres') == 'Action'\n",
    "\n",
    "filtered_results = perform_query(query, k=NUM_RESULTS, filter=filter_condition)\n",
    "enriched_results = enrich_documents(filtered_results)\n",
    "print ('** METADATA:\\n')\n",
    "print (f'{enriched_results[0][0].metadata}\\n')\n",
    "print ('** PAGE CONTENT:\\n')\n",
    "print (f'{enriched_results[0][0].page_content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d4ea3-61b0-4cd0-a4ce-7cc957e230df",
   "metadata": {},
   "source": [
    "## SECTION 6 - READABILITY\n",
    "\n",
    "The following two functions will improve readability by formatting results into a Markdown table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bfc08",
   "metadata": {},
   "source": [
    "### Function to display a markdown table with search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e223de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(list_of_movies, ignore_movie_id=None):\n",
    "    markdown = \"\"\n",
    "    total_movies = len(list_of_movies)\n",
    "    print(f\"Total number of movies below: {total_movies}\\n\")\n",
    "    markdown += \"| Movie Name   | Movie Information |\\n\"\n",
    "    markdown += \"|--------------|-------------------|\\n\"\n",
    "    for movie in list_of_movies:\n",
    "        doc = movie[0]\n",
    "        vss_score = movie[1]\n",
    "        metadata = doc.metadata\n",
    "        if 'id' in doc.metadata and doc.metadata['id'] != ignore_movie_id:\n",
    "            markdown += get_cell_info_from_movie(movie, vss_score)\n",
    "        else:\n",
    "            continue\n",
    "    display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e8283",
   "metadata": {},
   "source": [
    "### Function to populate a Markdown table with movie information\n",
    "\n",
    "This is called one time per movie from the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_info_from_movie(movie, relevance_score=0.0):\n",
    "    movie_cell = \"\"\n",
    "    doc = movie[0]\n",
    "    movie_name_cell = \"\"\n",
    "    metadata = doc.metadata\n",
    "    if 'movie_name' in metadata:\n",
    "        movie_name = metadata['movie_name']\n",
    "        movie_name_cell += f\"|**{movie_name}**|\"\n",
    "    else:\n",
    "        movie_name_cell = \"||\"\n",
    "    movie_name_cell = f\"|**{movie_name}**|\"\n",
    "    movie_data_cell = \"\"\n",
    "    if 'plot' in metadata:\n",
    "        plot_text = metadata['plot'][:MAX_PLOT_LENGTH] + '...'\n",
    "        movie_data_cell += f\"**Plot**: {plot_text}<p><p>\"\n",
    "    if 'actors' in metadata:\n",
    "        movie_data_cell += f\"**Actors**: {metadata['actors']}<p><p>\"\n",
    "    if 'id' in metadata:\n",
    "        movie_data_cell += f\"**MemoryDB keyname**: {metadata['id']}<p><p>\"\n",
    "    if 'genres' in metadata:\n",
    "        movie_data_cell += f\"**Genres**: {metadata['genres']}<p><p>\"\n",
    "    movie_data_cell += f\"**Relevance Score**: {relevance_score}<p>\"\n",
    "    movie_data_cell += \"|\"\n",
    "    return movie_name_cell + movie_data_cell + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ae557",
   "metadata": {},
   "source": [
    "### Simplifying it\n",
    "\n",
    "This function simplifies the process of performing a search, enriching the documents, and displaying the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_display_results(query, k):\n",
    "    results = perform_query(query=query, k=k)\n",
    "    enriched_documents = enrich_documents(results)\n",
    "    display_results(enriched_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09265a78",
   "metadata": {},
   "source": [
    "### Now run the above function\n",
    "\n",
    "Everything up until now is so we can easily search for, and display, results from a query. Let's get an initial list of 10 movies to review.\n",
    "\n",
    "Notice that each row contains a `MemoryDB keyname`. This will be used in a follow-up step.\n",
    "\n",
    "Modify the value of `k` to change the number of results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69732835",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_and_display_results(query=query, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6605e",
   "metadata": {},
   "source": [
    "## SECTION 7 - ACTUAL RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949888d",
   "metadata": {},
   "source": [
    "Up until now we have searched on a collection of words that we manually provided. Now we want to provide actual recommendations to our user based on the movie they just watched. So let's create a function that does the following:\n",
    "\n",
    "1. Takes a document ID (then unique ID of the movie our user just watched).\n",
    "2. Gets the metadata for that movie.\n",
    "3. Gets the vector data (the `content_vector` field), which contains a vector of the combined values of `movie name`, `genres`, `actors` and `plot`.\n",
    "4. Takes that vector data and performs a vector similarity search with it. This provides a list of movies based on the similarity of all of these fields.\n",
    "5. Enriches the movie information with the metadata stored in MemoryDB.\n",
    "6. Displays the enriched data in a Markdown table (without displaying the original movie).\n",
    "\n",
    "**Why are we performing a vector search against the vector data of an existing record?** We do this because we are simulating a user who has just watched a movie that they like, and we are recommending similar movies to it. We are basing this on the fact that the user might like the movie plot, genres, actors and movie name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_from_id(_doc_id, k=15):\n",
    "    mdb_value = get_metadata_from_mdb(_doc_id)\n",
    "    content = mdb_value['content']\n",
    "    results = perform_query(content, k=k)\n",
    "    enriched_documents = enrich_documents(results)\n",
    "    display_results(enriched_documents, _doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51090062",
   "metadata": {},
   "source": [
    "## Testing recommendations\n",
    "\n",
    "Now copy the `MemoryDB keyname:` value from one of the movies in the Markdown table above, and run this cell to see recommendations based on that movie!\n",
    "\n",
    "Feel free to run this multiple times with different movie ID's (`MemoryDB keyname`) to see the results! \n",
    "\n",
    "You can also modify the `k` value to change the number of results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f72a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_ID = ''\n",
    "\n",
    "show_results_from_id(MOVIE_ID, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca52b80",
   "metadata": {},
   "source": [
    "## SECTION 8 - SUMMARY\n",
    "\n",
    "In this demo you have used a movie dataset, created vectorized embeddings, stored those in MemoryDB, and then received recommendations based off both search terms as well as **recommendations** based off of a specific movie id.\n",
    "\n",
    "Click to learn more about [MemoryDB's vector search capabilities](https://docs.aws.amazon.com/memorydb/latest/devguide/vector-search-overview.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
